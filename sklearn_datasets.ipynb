{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "from metrics import ModelChooser\n",
    "from helpers import plot_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 7\n",
    "\n",
    "LR_ARGS = {\"solver\": 'lbfgs', \"max_iter\": 10000}\n",
    "RF_ARGS = {\"n_estimators\": 40, \"n_jobs\": -1, \"random_state\": RANDOM_SEED}\n",
    "\n",
    "\n",
    "MC = ModelChooser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lr(x_train, y_train, x_test, y_test):\n",
    "    lr = LogisticRegression(**LR_ARGS)\n",
    "    lr.fit(x_train, y_train)\n",
    "    \n",
    "    ppreds_t = lr.predict_proba(x_train)\n",
    "    preds_t = np.argmax(ppreds_t, axis=1)\n",
    "    ppreds_v = lr.predict_proba(x_test)\n",
    "    preds_v = np.argmax(ppreds_v, axis=1)\n",
    "    \n",
    "    print(\"Train acc:\", accuracy_score(y_train, preds_t))\n",
    "    print(\"Test acc:\", accuracy_score(y_test, preds_v))\n",
    "    \n",
    "def train_rf(x_train, y_train, x_test, y_test):\n",
    "    rf = RandomForestClassifier(**RF_ARGS)\n",
    "    rf.fit(x_train, y_train)\n",
    "    \n",
    "    ppreds_t = rf.predict_proba(x_train)\n",
    "    preds_t = np.argmax(ppreds_t, axis=1)\n",
    "    ppreds_v = rf.predict_proba(x_test)\n",
    "    preds_v = np.argmax(ppreds_v, axis=1)\n",
    "    \n",
    "    print(\"Train acc:\", accuracy_score(y_train, preds_t))\n",
    "    print(\"Test acc:\", accuracy_score(y_test, preds_v))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcd = datasets.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bcd['data']\n",
    "y = bcd['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.964824120603015\n",
      "Test acc: 0.9590643274853801\n"
     ]
    }
   ],
   "source": [
    "train_lr(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.0\n",
      "Test acc: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "train_rf(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature distribution summary:\n",
      " {'logit': [0, 2, 3, 5, 6, 7, 10, 12, 13, 20, 22, 23, 25, 26, 27], 'internal_sep': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], 'half-logit': [1, 4, 8, 15, 16, 17, 19, 21, 24, 28, 29]}\n",
      "\n",
      "Logistic Regression is the better option\n"
     ]
    }
   ],
   "source": [
    "MC.decide(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_one(y):\n",
    "    y_orig = y.copy()\n",
    "    y_working = y_orig.copy()\n",
    "    classes = np.unique(y_orig)\n",
    "    res = []\n",
    "    for c in classes:\n",
    "        if c == 0:\n",
    "            # cant directly set to 0 as c is 0, and cant make c 1 cause some other classes may be 1\n",
    "            y_working[y_orig!=c] = -1\n",
    "            y_working[y_orig==c] = 1\n",
    "            y_working[y_orig!=c] = 0\n",
    "        else:\n",
    "            y_working[y_orig!=c] = 0\n",
    "            y_working[y_orig==c] = 1\n",
    "        res.append(y_working.copy())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ird = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = choose_one(ird['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision:\n",
      "Feature distribution summary:\n",
      " {'logit': [0, 1, 2, 3], 'internal_sep': [0, 1, 2, 3], 'half-logit': []}\n",
      "\n",
      "Logistic Regression is the better option\n",
      "\n",
      "\n",
      "LR:\n",
      "Train acc: 1.0\n",
      "Test acc: 1.0\n",
      "\n",
      "RF:\n",
      "Train acc: 1.0\n",
      "Test acc: 1.0\n",
      "-----------\n",
      "\n",
      "Decision:\n",
      "Feature distribution summary:\n",
      " {'logit': [], 'internal_sep': [0, 1, 2, 3], 'half-logit': [1]}\n",
      "\n",
      "Random Forest is the better option\n",
      "\n",
      "\n",
      "LR:\n",
      "Train acc: 0.7904761904761904\n",
      "Test acc: 0.6222222222222222\n",
      "\n",
      "RF:\n",
      "Train acc: 1.0\n",
      "Test acc: 0.9111111111111111\n",
      "-----------\n",
      "\n",
      "Decision:\n",
      "Feature distribution summary:\n",
      " {'logit': [0, 2, 3], 'internal_sep': [0, 1, 2, 3], 'half-logit': [1]}\n",
      "\n",
      "Logistic Regression is the better option\n",
      "\n",
      "\n",
      "LR:\n",
      "Train acc: 0.9904761904761905\n",
      "Test acc: 0.9111111111111111\n",
      "\n",
      "RF:\n",
      "Train acc: 1.0\n",
      "Test acc: 0.9111111111111111\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = ird['data']\n",
    "for y in opts:\n",
    "    print(\"Decision:\")\n",
    "    MC.decide(x, y)\n",
    "    print('\\n')\n",
    "    \n",
    "    print(\"LR:\")\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    train_lr(x_train, y_train, x_test, y_test)\n",
    "    print(\"\\nRF:\")\n",
    "    train_rf(x_train, y_train, x_test, y_test)\n",
    "    print(\"-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_1d(x, opts[1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = sklearn.datasets.load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = choose_one(wd['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision:\n",
      "Feature distribution summary:\n",
      " {'logit': [0, 3, 5, 6, 12], 'internal_sep': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'half-logit': [2, 4, 7, 8, 9, 10, 11]}\n",
      "\n",
      "Logistic Regression is the better option\n",
      "\n",
      "\n",
      "Train acc: 0.9919354838709677\n",
      "Test acc: 0.9814814814814815\n",
      "Train acc: 1.0\n",
      "Test acc: 1.0\n",
      "-----------\n",
      "\n",
      "Decision:\n",
      "Feature distribution summary:\n",
      " {'logit': [0, 1, 4, 9, 12], 'internal_sep': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'half-logit': [2, 3, 8, 10, 11]}\n",
      "\n",
      "Logistic Regression is the better option\n",
      "\n",
      "\n",
      "Train acc: 0.9838709677419355\n",
      "Test acc: 0.9629629629629629\n",
      "Train acc: 1.0\n",
      "Test acc: 1.0\n",
      "-----------\n",
      "\n",
      "Decision:\n",
      "Feature distribution summary:\n",
      " {'logit': [5, 6, 10, 11], 'internal_sep': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'half-logit': [1, 2, 3, 7, 8, 9]}\n",
      "\n",
      "Logistic Regression is the better option\n",
      "\n",
      "\n",
      "Train acc: 1.0\n",
      "Test acc: 0.9629629629629629\n",
      "Train acc: 1.0\n",
      "Test acc: 1.0\n",
      "-----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = wd['data']\n",
    "for y in opts:\n",
    "    print(\"Decision:\")\n",
    "    MC.decide(x, y)\n",
    "    print('\\n')\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_SEED)\n",
    "    lr = train_lr(x_train, y_train, x_test, y_test)\n",
    "    train_rf(x_train, y_train, x_test, y_test)\n",
    "    print(\"-----------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_classification(y):\n",
    "    y_out = np.zeros(len(y))\n",
    "    m = y.mean()\n",
    "    y_out[y >= m] = 1\n",
    "    return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = sklearn.datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bd['data']\n",
    "y = to_classification(bd['target'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature distribution summary:\n",
      " {'logit': [2, 5, 6, 12], 'internal_sep': [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'half-logit': [0, 1, 4, 7, 8, 9, 10, 11]}\n",
      "\n",
      "Logistic Regression is the better option\n"
     ]
    }
   ],
   "source": [
    "MC.decide(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9067796610169492\n",
      "Test acc: 0.8486842105263158\n"
     ]
    }
   ],
   "source": [
    "train_lr(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.0\n",
      "Test acc: 0.8486842105263158\n"
     ]
    }
   ],
   "source": [
    "train_rf(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
